[2025-08-26 18:43:33.707] [71488] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 18:43:33.711] [71488] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 18:43:33.712] [71488] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 18:43:33.782] [71488] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 18:43:33.783] [71488] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 18:43:33.784] [71488] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 18:43:43.842] [71516] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 18:43:43.843] [71516] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 18:43:43.844] [71516] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 18:43:43.871] [71516] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-26 18:43:44.934] [71516] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 18:43:44.935] [71516] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 18:43:44.963] [71516] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 18:43:44.963] [71516] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 18:43:45.049] [71516] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-26 18:43:45.051] [71516] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-26 18:43:45.051] [71516] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-26 18:43:45.051] [71516] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-26 18:43:45.052] [71516] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-26 18:43:45.052] [71516] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-26 18:43:45.053] [71516] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-26 18:43:45.053] [71516] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-26 18:43:45.053] [71516] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 71602)
[2025-08-26 18:43:45.053] [71516] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-26 18:43:45.053] [71516] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 71603)
[2025-08-26 18:43:45.053] [71516] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-26 18:43:45.053] [71516] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 71604)
[2025-08-26 18:43:45.053] [71516] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-26 18:43:45.053] [71516] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-26 18:43:45.053] [71516] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 18:43:45.053] [71516] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 18:48:25.626] [71488] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-26 18:48:25.627] [71488] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 18:48:25.627] [71488] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 18:48:25.627] [71488] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 18:48:25.627] [71488] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 18:48:25.627] [71488] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 18:48:25.627] [71488] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 18:48:25.627] [71488] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl3meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 18:48:25.627] [71488] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element EntryPushQEl0meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 18:48:25.627] [71488] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element EntryPushQEl0meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-26 18:48:25.627] [71488] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl3meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-26 18:48:25.628] [71600] [HailoRT] [info] [vdevice.cpp:424] [listener_run_in_thread] Shutdown event was signaled in listener_run_in_thread
[2025-08-26 18:49:09.386] [75158] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 18:49:09.387] [75158] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 18:49:09.388] [75158] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 18:49:09.449] [75158] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 18:49:09.450] [75158] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 18:49:09.451] [75158] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 18:49:18.561] [75173] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 18:49:18.562] [75173] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 18:49:18.563] [75173] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 18:49:18.598] [75173] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-26 18:49:19.614] [75173] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 18:49:19.616] [75173] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 18:49:19.641] [75173] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 18:49:19.641] [75173] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 18:49:19.709] [75173] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-26 18:49:19.709] [75173] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-26 18:49:19.710] [75173] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-26 18:49:19.710] [75173] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-26 18:49:19.710] [75173] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-26 18:49:19.711] [75173] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-26 18:49:19.711] [75173] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-26 18:49:19.711] [75173] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-26 18:49:19.711] [75173] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 75266)
[2025-08-26 18:49:19.711] [75173] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-26 18:49:19.711] [75173] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 75267)
[2025-08-26 18:49:19.711] [75173] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-26 18:49:19.711] [75173] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 75268)
[2025-08-26 18:49:19.711] [75173] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-26 18:49:19.711] [75173] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-26 18:49:19.711] [75173] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 18:49:19.711] [75173] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 19:05:04.632] [75158] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-26 19:05:04.633] [75158] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:05:04.633] [75158] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:05:04.633] [75158] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:05:04.633] [75158] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:05:04.633] [75158] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:05:04.633] [75158] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:05:04.633] [75158] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl3meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:05:04.633] [75158] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element EntryPushQEl0meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:05:04.633] [75158] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element EntryPushQEl0meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-26 19:05:04.633] [75158] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl3meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-26 19:05:04.634] [75264] [HailoRT] [info] [vdevice.cpp:424] [listener_run_in_thread] Shutdown event was signaled in listener_run_in_thread
[2025-08-26 19:06:05.450] [84891] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:06:05.451] [84891] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:06:05.452] [84891] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:06:05.505] [84891] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:06:05.506] [84891] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:06:05.507] [84891] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:06:42.607] [84909] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:06:42.608] [84909] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:06:42.609] [84909] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:06:42.646] [84909] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-26 19:06:43.662] [84909] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:06:43.663] [84909] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:06:43.688] [84909] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 19:06:43.688] [84909] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 19:06:43.758] [84909] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-26 19:06:43.758] [84909] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-26 19:06:43.759] [84909] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-26 19:06:43.759] [84909] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-26 19:06:43.759] [84909] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-26 19:06:43.760] [84909] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-26 19:06:43.760] [84909] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-26 19:06:43.760] [84909] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-26 19:06:43.760] [84909] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 85095)
[2025-08-26 19:06:43.760] [84909] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-26 19:06:43.760] [84909] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 85096)
[2025-08-26 19:06:43.760] [84909] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-26 19:06:43.760] [84909] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 85097)
[2025-08-26 19:06:43.760] [84909] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-26 19:06:43.760] [84909] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-26 19:06:43.760] [84909] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 19:06:43.760] [84909] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 19:11:12.184] [84891] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-26 19:11:12.185] [84891] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:11:12.185] [84891] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:11:12.185] [84891] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:11:12.185] [84891] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:11:12.185] [84891] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:11:12.185] [84891] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:11:12.185] [84891] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl3meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:11:12.185] [84891] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element EntryPushQEl0meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:11:12.185] [84891] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element EntryPushQEl0meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-26 19:11:12.185] [84891] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl3meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-26 19:11:12.187] [85093] [HailoRT] [info] [vdevice.cpp:424] [listener_run_in_thread] Shutdown event was signaled in listener_run_in_thread
[2025-08-26 19:11:21.181] [87641] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:11:21.183] [87641] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:11:21.183] [87641] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:11:21.241] [87641] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:11:21.243] [87641] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:11:21.243] [87641] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:12:51.998] [87817] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:12:52.000] [87817] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:12:52.001] [87817] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:12:52.057] [87817] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:12:52.058] [87817] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:12:52.059] [87817] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:13:57.710] [87981] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:13:57.711] [87981] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:13:57.712] [87981] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:13:57.769] [87981] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:13:57.770] [87981] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:13:57.771] [87981] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:14:04.874] [88001] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:14:04.876] [88001] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:14:04.876] [88001] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:14:04.906] [88001] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-26 19:14:05.923] [88001] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:14:05.924] [88001] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:14:05.951] [88001] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 19:14:05.951] [88001] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 19:14:06.013] [88001] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-26 19:14:06.013] [88001] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-26 19:14:06.014] [88001] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-26 19:14:06.014] [88001] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-26 19:14:06.014] [88001] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-26 19:14:06.014] [88001] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-26 19:14:06.015] [88001] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-26 19:14:06.015] [88001] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-26 19:14:06.015] [88001] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 88080)
[2025-08-26 19:14:06.015] [88001] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-26 19:14:06.015] [88001] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 88081)
[2025-08-26 19:14:06.015] [88001] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-26 19:14:06.015] [88001] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 88082)
[2025-08-26 19:14:06.015] [88001] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-26 19:14:06.015] [88001] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-26 19:14:06.015] [88001] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 19:14:06.015] [88001] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 19:15:03.320] [87981] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-26 19:15:03.321] [87981] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:15:03.321] [87981] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:15:03.321] [87981] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:15:03.321] [87981] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:15:03.321] [87981] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:15:03.321] [87981] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:15:03.321] [87981] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl3meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:15:03.321] [87981] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element EntryPushQEl0meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 19:15:03.321] [87981] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element EntryPushQEl0meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-26 19:15:03.321] [87981] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl3meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-26 19:15:03.322] [88078] [HailoRT] [info] [vdevice.cpp:424] [listener_run_in_thread] Shutdown event was signaled in listener_run_in_thread
[2025-08-26 19:22:05.892] [89237] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:22:05.894] [89237] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:22:05.895] [89237] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:22:05.954] [89237] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:22:05.955] [89237] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:22:05.956] [89237] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:22:11.547] [89255] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:22:11.548] [89255] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:22:11.549] [89255] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:22:11.574] [89255] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-26 19:22:12.591] [89255] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:22:12.592] [89255] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:22:12.620] [89255] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 19:22:12.620] [89255] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 19:22:12.681] [89255] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-26 19:22:12.682] [89255] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-26 19:22:12.682] [89255] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-26 19:22:12.682] [89255] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-26 19:22:12.682] [89255] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-26 19:22:12.683] [89255] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-26 19:22:12.683] [89255] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-26 19:22:12.683] [89255] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-26 19:22:12.683] [89255] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 89336)
[2025-08-26 19:22:12.683] [89255] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-26 19:22:12.683] [89255] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 89337)
[2025-08-26 19:22:12.683] [89255] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-26 19:22:12.683] [89255] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 89338)
[2025-08-26 19:22:12.683] [89255] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-26 19:22:12.683] [89255] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-26 19:22:12.683] [89255] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 19:22:12.683] [89255] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 19:23:54.744] [1300] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:23:54.748] [1300] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:23:54.749] [1300] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:23:54.952] [1300] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:23:54.953] [1300] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:23:54.954] [1300] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:25:45.200] [1697] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:25:45.201] [1697] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:25:45.202] [1697] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:25:45.234] [1697] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-26 19:25:46.294] [1697] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 19:25:46.295] [1697] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 19:25:46.338] [1697] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 19:25:46.338] [1697] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 19:25:46.421] [1697] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-26 19:25:46.423] [1697] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-26 19:25:46.423] [1697] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-26 19:25:46.423] [1697] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-26 19:25:46.424] [1697] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-26 19:25:46.424] [1697] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-26 19:25:46.424] [1697] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-26 19:25:46.424] [1697] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-26 19:25:46.424] [1697] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 1927)
[2025-08-26 19:25:46.424] [1697] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-26 19:25:46.424] [1697] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 1928)
[2025-08-26 19:25:46.424] [1697] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-26 19:25:46.424] [1697] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 1929)
[2025-08-26 19:25:46.424] [1697] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-26 19:25:46.424] [1697] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-26 19:25:46.425] [1697] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 19:25:46.425] [1697] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 23:32:20.438] [1286] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 23:32:20.442] [1286] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 23:32:20.442] [1286] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 23:32:20.636] [1286] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 23:32:20.637] [1286] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 23:32:20.638] [1286] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 23:34:45.339] [1686] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 23:34:45.340] [1686] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 23:34:45.341] [1686] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 23:34:45.373] [1686] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-26 23:34:46.430] [1686] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 23:34:46.432] [1686] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 23:34:46.465] [1686] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 23:34:46.465] [1686] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 23:34:46.545] [1686] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-26 23:34:46.546] [1686] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-26 23:34:46.547] [1686] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-26 23:34:46.547] [1686] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-26 23:34:46.547] [1686] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-26 23:34:46.548] [1686] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-26 23:34:46.548] [1686] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-26 23:34:46.548] [1686] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-26 23:34:46.548] [1686] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 1929)
[2025-08-26 23:34:46.548] [1686] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-26 23:34:46.548] [1686] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 1930)
[2025-08-26 23:34:46.548] [1686] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-26 23:34:46.548] [1686] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 1931)
[2025-08-26 23:34:46.548] [1686] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-26 23:34:46.548] [1686] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-26 23:34:46.548] [1686] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 23:34:46.548] [1686] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 23:38:36.151] [1286] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-26 23:38:36.152] [1286] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 23:38:36.152] [1286] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 23:38:36.152] [1286] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 23:38:36.152] [1286] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 23:38:36.152] [1286] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 23:38:36.152] [1286] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 23:38:36.152] [1286] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl3meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 23:38:36.152] [1286] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element EntryPushQEl0meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-26 23:38:36.152] [1286] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element EntryPushQEl0meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-26 23:38:36.152] [1286] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl3meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-26 23:38:36.153] [1927] [HailoRT] [info] [vdevice.cpp:424] [listener_run_in_thread] Shutdown event was signaled in listener_run_in_thread
[2025-08-26 23:47:31.423] [6367] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 23:47:31.425] [6367] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 23:47:31.426] [6367] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 23:47:31.486] [6367] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 23:47:31.488] [6367] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 23:47:31.489] [6367] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 23:47:36.212] [6393] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 23:47:36.220] [6393] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 23:47:36.221] [6393] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 23:47:36.255] [6393] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-26 23:47:37.273] [6393] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-26 23:47:37.274] [6393] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-26 23:47:37.299] [6393] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 23:47:37.299] [6393] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 23:47:37.371] [6393] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-26 23:47:37.373] [6393] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-26 23:47:37.375] [6393] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-26 23:47:37.375] [6393] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-26 23:47:37.375] [6393] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-26 23:47:37.377] [6393] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-26 23:47:37.378] [6393] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-26 23:47:37.378] [6393] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-26 23:47:37.378] [6393] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 6484)
[2025-08-26 23:47:37.378] [6393] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-26 23:47:37.378] [6393] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 6485)
[2025-08-26 23:47:37.378] [6393] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-26 23:47:37.378] [6393] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 6486)
[2025-08-26 23:47:37.378] [6393] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-26 23:47:37.378] [6393] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-26 23:47:37.378] [6393] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-26 23:47:37.378] [6393] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 00:19:20.402] [6367] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-27 00:19:20.403] [6367] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:19:20.403] [6367] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:19:20.403] [6367] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:19:20.403] [6367] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:19:20.403] [6367] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:19:20.403] [6367] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:19:20.403] [6367] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl3meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:19:20.403] [6367] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element EntryPushQEl0meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:19:20.403] [6367] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element EntryPushQEl0meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-27 00:19:20.403] [6367] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl3meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-27 00:19:20.404] [6482] [HailoRT] [info] [vdevice.cpp:424] [listener_run_in_thread] Shutdown event was signaled in listener_run_in_thread
[2025-08-27 00:22:39.839] [15374] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 00:22:39.840] [15374] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:22:39.841] [15374] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:22:39.890] [15374] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 00:22:39.891] [15374] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:22:39.892] [15374] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:23:58.365] [15389] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 00:23:58.366] [15389] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:23:58.368] [15389] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:23:58.411] [15389] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-27 00:23:59.427] [15389] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 00:23:59.429] [15389] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:23:59.454] [15389] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 00:23:59.454] [15389] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 00:23:59.513] [15389] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-27 00:23:59.514] [15389] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-27 00:23:59.514] [15389] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 00:23:59.514] [15389] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-27 00:23:59.514] [15389] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 00:23:59.515] [15389] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-27 00:23:59.515] [15389] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-27 00:23:59.515] [15389] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-27 00:23:59.515] [15389] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 15723)
[2025-08-27 00:23:59.515] [15389] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-27 00:23:59.515] [15389] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 15724)
[2025-08-27 00:23:59.515] [15389] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-27 00:23:59.515] [15389] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 15725)
[2025-08-27 00:23:59.515] [15389] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-27 00:23:59.515] [15389] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-27 00:23:59.515] [15389] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 00:23:59.515] [15389] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 00:25:08.198] [15374] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-27 00:25:08.198] [15374] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:25:08.198] [15374] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:25:08.198] [15374] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:25:08.198] [15374] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:25:08.198] [15374] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:25:08.198] [15374] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:25:08.198] [15374] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl3meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:25:08.198] [15374] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element EntryPushQEl0meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:25:08.198] [15374] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element EntryPushQEl0meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-27 00:25:08.198] [15374] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl3meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-27 00:25:08.200] [15721] [HailoRT] [info] [vdevice.cpp:424] [listener_run_in_thread] Shutdown event was signaled in listener_run_in_thread
[2025-08-27 00:28:20.155] [17260] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 00:28:20.156] [17260] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:28:20.157] [17260] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:28:20.218] [17260] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 00:28:20.219] [17260] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:28:20.220] [17260] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:28:40.095] [17275] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 00:28:40.098] [17275] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:28:40.100] [17275] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:28:40.127] [17275] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-27 00:28:41.144] [17275] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 00:28:41.145] [17275] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:28:41.169] [17275] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 00:28:41.169] [17275] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 00:28:41.228] [17275] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-27 00:28:41.229] [17275] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-27 00:28:41.230] [17275] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 00:28:41.230] [17275] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-27 00:28:41.230] [17275] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 00:28:41.230] [17275] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-27 00:28:41.231] [17275] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-27 00:28:41.231] [17275] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-27 00:28:41.231] [17275] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 17408)
[2025-08-27 00:28:41.231] [17275] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-27 00:28:41.231] [17275] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 17409)
[2025-08-27 00:28:41.231] [17275] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-27 00:28:41.231] [17275] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 17410)
[2025-08-27 00:28:41.231] [17275] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-27 00:28:41.231] [17275] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-27 00:28:41.231] [17275] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 00:28:41.231] [17275] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 00:34:38.576] [17260] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-27 00:34:38.576] [17260] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:34:38.576] [17260] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:34:38.576] [17260] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:34:38.576] [17260] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:34:38.576] [17260] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:34:38.576] [17260] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:34:38.576] [17260] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl3meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:34:38.576] [17260] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element EntryPushQEl0meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 00:34:38.576] [17260] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element EntryPushQEl0meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-27 00:34:38.576] [17260] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl3meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-27 00:34:38.577] [17406] [HailoRT] [info] [vdevice.cpp:424] [listener_run_in_thread] Shutdown event was signaled in listener_run_in_thread
[2025-08-27 00:34:43.335] [19789] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 00:34:43.336] [19789] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:34:43.337] [19789] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:34:43.390] [19789] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 00:34:43.392] [19789] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:34:43.393] [19789] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:34:54.763] [19804] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 00:34:54.764] [19804] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:34:54.765] [19804] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:34:54.791] [19804] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-27 00:34:55.807] [19804] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 00:34:55.808] [19804] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:34:55.832] [19804] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 00:34:55.832] [19804] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 00:34:55.894] [19804] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-27 00:34:55.895] [19804] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-27 00:34:55.895] [19804] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 00:34:55.895] [19804] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-27 00:34:55.895] [19804] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 00:34:55.896] [19804] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-27 00:34:55.896] [19804] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-27 00:34:55.896] [19804] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-27 00:34:55.896] [19804] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 19905)
[2025-08-27 00:34:55.896] [19804] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-27 00:34:55.896] [19804] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 19906)
[2025-08-27 00:34:55.896] [19804] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-27 00:34:55.896] [19804] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 19907)
[2025-08-27 00:34:55.897] [19804] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-27 00:34:55.897] [19804] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-27 00:34:55.897] [19804] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 00:34:55.897] [19804] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 00:46:51.078] [1414] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 00:46:51.081] [1414] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:46:51.082] [1414] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:46:51.280] [1414] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 00:46:51.281] [1414] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:46:51.282] [1414] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:46:55.912] [1756] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 00:46:55.915] [1756] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:46:55.918] [1756] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:46:55.950] [1756] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-27 00:46:57.009] [1756] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 00:46:57.010] [1756] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 00:46:57.042] [1756] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 00:46:57.042] [1756] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 00:46:57.126] [1756] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-27 00:46:57.127] [1756] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-27 00:46:57.128] [1756] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 00:46:57.128] [1756] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-27 00:46:57.128] [1756] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 00:46:57.129] [1756] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-27 00:46:57.129] [1756] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-27 00:46:57.129] [1756] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-27 00:46:57.129] [1756] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 1813)
[2025-08-27 00:46:57.129] [1756] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-27 00:46:57.129] [1756] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 1814)
[2025-08-27 00:46:57.129] [1756] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-27 00:46:57.129] [1756] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 1815)
[2025-08-27 00:46:57.129] [1756] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-27 00:46:57.129] [1756] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-27 00:46:57.129] [1756] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressi[2025-08-27 10:51:33.765] [2717] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 10:51:33.767] [2717] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:51:33.768] [2717] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:51:33.817] [2717] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 10:51:33.819] [2717] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:51:33.820] [2717] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:51:38.453] [2737] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 10:51:38.455] [2737] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:51:38.456] [2737] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:51:38.493] [2737] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-27 10:51:39.510] [2737] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 10:51:39.511] [2737] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:51:39.539] [2737] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 10:51:39.539] [2737] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 10:51:39.606] [2737] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-27 10:51:39.607] [2737] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-27 10:51:39.608] [2737] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 10:51:39.608] [2737] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-27 10:51:39.608] [2737] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 10:51:39.609] [2737] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-27 10:51:39.610] [2737] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-27 10:51:39.610] [2737] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-27 10:51:39.610] [2737] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 2813)
[2025-08-27 10:51:39.610] [2737] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-27 10:51:39.610] [2737] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 2814)
[2025-08-27 10:51:39.610] [2737] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-27 10:51:39.610] [2737] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 2815)
[2025-08-27 10:51:39.610] [2737] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-27 10:51:39.610] [2737] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-27 10:51:39.610] [2737] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressi[2025-08-27 10:52:24.421] [2868] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 10:52:24.423] [2868] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:52:24.423] [2868] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:52:24.484] [2868] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 10:52:24.486] [2868] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:52:24.487] [2868] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:52:29.192] [2883] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 10:52:29.194] [2883] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:52:29.195] [2883] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:52:29.233] [2883] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-27 10:52:30.250] [2883] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 10:52:30.251] [2883] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:52:30.278] [2883] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 10:52:30.278] [2883] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 10:52:30.354] [2883] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-27 10:52:30.355] [2883] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-27 10:52:30.356] [2883] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 10:52:30.356] [2883] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-27 10:52:30.356] [2883] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 10:52:30.356] [2883] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-27 10:52:30.357] [2883] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-27 10:52:30.357] [2883] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-27 10:52:30.357] [2883] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 2954)
[2025-08-27 10:52:30.357] [2883] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-27 10:52:30.357] [2883] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 2955)
[2025-08-27 10:52:30.357] [2883] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-27 10:52:30.357] [2883] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 2956)
[2025-08-27 10:52:30.357] [2883] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-27 10:52:30.357] [2883] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-27 10:52:30.357] [2883] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 10:52:30.357] [2883] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 10:55:01.850] [1289] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 10:55:01.853] [1289] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:55:01.854] [1289] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:55:02.054] [1289] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 10:55:02.056] [1289] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:55:02.056] [1289] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:55:06.687] [1689] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 10:55:06.688] [1689] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:55:06.689] [1689] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:55:06.718] [1689] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-27 10:55:07.775] [1689] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 10:55:07.776] [1689] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 10:55:07.809] [1689] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 10:55:07.809] [1689] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 10:55:07.898] [1689] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-27 10:55:07.899] [1689] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-27 10:55:07.900] [1689] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 10:55:07.900] [1689] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-27 10:55:07.900] [1689] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 10:55:07.901] [1689] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-27 10:55:07.901] [1689] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-27 10:55:07.901] [1689] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-27 10:55:07.901] [1689] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 1801)
[2025-08-27 10:55:07.901] [1689] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-27 10:55:07.901] [1689] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 1802)
[2025-08-27 10:55:07.901] [1689] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-27 10:55:07.901] [1689] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 1803)
[2025-08-27 10:55:07.901] [1689] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-27 10:55:07.901] [1689] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-27 10:55:07.901] [1689] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressi[2025-08-27 11:15:55.834] [1283] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:15:55.838] [1283] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:15:55.838] [1283] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:15:56.044] [1283] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:15:56.045] [1283] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:15:56.046] [1283] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:16:00.491] [1741] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:16:00.492] [1741] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:16:00.493] [1741] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:16:00.526] [1741] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-27 11:16:01.586] [1741] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:16:01.587] [1741] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:16:01.622] [1741] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 11:16:01.622] [1741] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 11:16:01.726] [1741] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-27 11:16:01.727] [1741] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-27 11:16:01.728] [1741] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 11:16:01.728] [1741] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-27 11:16:01.728] [1741] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 11:16:01.729] [1741] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-27 11:16:01.729] [1741] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-27 11:16:01.729] [1741] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-27 11:16:01.729] [1741] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 1793)
[2025-08-27 11:16:01.729] [1741] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-27 11:16:01.729] [1741] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 1794)
[2025-08-27 11:16:01.729] [1741] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-27 11:16:01.729] [1741] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 1795)
[2025-08-27 11:16:01.729] [1741] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-27 11:16:01.729] [1741] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-27 11:16:01.730] [1741] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressi[2025-08-27 11:20:30.872] [1254] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:20:30.876] [1254] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:20:30.877] [1254] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:20:31.095] [1254] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:20:31.096] [1254] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:20:31.097] [1254] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:20:35.779] [1691] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:20:35.780] [1691] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:20:35.781] [1691] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:20:35.813] [1691] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-27 11:20:36.872] [1691] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:20:36.874] [1691] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:20:36.908] [1691] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 11:20:36.908] [1691] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 11:20:36.989] [1691] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-27 11:20:36.990] [1691] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-27 11:20:36.991] [1691] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 11:20:36.991] [1691] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-27 11:20:36.991] [1691] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 11:20:36.992] [1691] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-27 11:20:36.992] [1691] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-27 11:20:36.992] [1691] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-27 11:20:36.992] [1691] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 1805)
[2025-08-27 11:20:36.992] [1691] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-27 11:20:36.992] [1691] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 1806)
[2025-08-27 11:20:36.992] [1691] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-27 11:20:36.992] [1691] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 1807)
[2025-08-27 11:20:36.992] [1691] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-27 11:20:36.992] [1691] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-27 11:20:36.993] [1691] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressi[2025-08-27 11:22:15.094] [2644] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:22:15.100] [2644] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:22:15.101] [2644] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:22:15.184] [2644] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:22:15.193] [2644] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:22:15.204] [2644] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:22:20.315] [2684] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:22:20.316] [2684] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:22:20.317] [2684] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:22:20.347] [2684] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-27 11:22:21.364] [2684] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:22:21.365] [2684] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:22:21.390] [2684] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 11:22:21.390] [2684] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 11:22:21.454] [2684] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-27 11:22:21.455] [2684] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-27 11:22:21.455] [2684] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 11:22:21.456] [2684] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-27 11:22:21.456] [2684] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 11:22:21.456] [2684] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-27 11:22:21.456] [2684] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-27 11:22:21.456] [2684] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-27 11:22:21.456] [2684] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 2776)
[2025-08-27 11:22:21.457] [2684] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-27 11:22:21.457] [2684] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 2777)
[2025-08-27 11:22:21.457] [2684] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-27 11:22:21.457] [2684] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 2778)
[2025-08-27 11:22:21.457] [2684] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-27 11:22:21.457] [2684] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-27 11:22:21.457] [2684] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 11:22:21.457] [2684] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 11:22:29.107] [2644] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-27 11:22:29.107] [2644] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 11:22:29.107] [2644] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 11:22:29.107] [2644] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 11:22:29.107] [2644] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 11:22:29.107] [2644] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 11:22:29.107] [2644] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 11:22:29.107] [2644] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl3meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 11:22:29.107] [2644] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element EntryPushQEl0meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 11:22:29.107] [2644] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element EntryPushQEl0meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-27 11:22:29.107] [2644] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl3meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-27 11:22:29.108] [2774] [HailoRT] [info] [vdevice.cpp:424] [listener_run_in_thread] Shutdown event was signaled in listener_run_in_thread
[2025-08-27 11:24:20.637] [2935] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:24:20.638] [2935] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:24:20.639] [2935] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:24:20.690] [2935] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:24:20.691] [2935] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:24:20.692] [2935] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:24:25.271] [2950] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:24:25.273] [2950] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:24:25.274] [2950] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:24:25.299] [2950] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-27 11:24:26.316] [2950] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:24:26.317] [2950] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:24:26.342] [2950] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 11:24:26.342] [2950] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 11:24:26.404] [2950] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-27 11:24:26.405] [2950] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-27 11:24:26.405] [2950] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 11:24:26.406] [2950] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-27 11:24:26.406] [2950] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 11:24:26.406] [2950] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-27 11:24:26.407] [2950] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-27 11:24:26.407] [2950] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-27 11:24:26.407] [2950] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 3001)
[2025-08-27 11:24:26.407] [2950] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-27 11:24:26.407] [2950] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 3002)
[2025-08-27 11:24:26.407] [2950] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-27 11:24:26.407] [2950] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 3003)
[2025-08-27 11:24:26.407] [2950] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-27 11:24:26.407] [2950] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-27 11:24:26.407] [2950] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 11:24:26.407] [2950] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 11:27:32.338] [1580] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:27:32.342] [1580] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:27:32.343] [1580] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:27:32.541] [1580] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:27:32.542] [1580] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:27:32.543] [1580] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:27:37.177] [1732] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:27:37.178] [1732] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:27:37.179] [1732] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:27:37.219] [1732] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-27 11:27:38.276] [1732] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:27:38.277] [1732] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:27:38.309] [1732] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 11:27:38.309] [1732] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 11:27:38.407] [1732] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-27 11:27:38.408] [1732] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-27 11:27:38.409] [1732] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 11:27:38.409] [1732] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-27 11:27:38.409] [1732] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 11:27:38.410] [1732] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-27 11:27:38.410] [1732] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-27 11:27:38.410] [1732] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-27 11:27:38.410] [1732] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 1785)
[2025-08-27 11:27:38.410] [1732] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-27 11:27:38.410] [1732] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 1786)
[2025-08-27 11:27:38.410] [1732] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-27 11:27:38.410] [1732] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 1787)
[2025-08-27 11:27:38.410] [1732] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-27 11:27:38.410] [1732] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-27 11:27:38.410] [1732] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressi[2025-08-27 11:39:07.282] [1539] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:39:07.286] [1539] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:39:07.287] [1539] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:39:07.481] [1539] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:39:07.482] [1539] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:39:07.483] [1539] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:39:12.116] [1734] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:39:12.117] [1734] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:39:12.118] [1734] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:39:12.158] [1734] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-27 11:39:13.217] [1734] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 11:39:13.218] [1734] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 11:39:13.252] [1734] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 11:39:13.252] [1734] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 11:39:13.350] [1734] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-27 11:39:13.352] [1734] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-27 11:39:13.352] [1734] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 11:39:13.352] [1734] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-27 11:39:13.352] [1734] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 11:39:13.353] [1734] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-27 11:39:13.353] [1734] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-27 11:39:13.353] [1734] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-27 11:39:13.353] [1734] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 1788)
[2025-08-27 11:39:13.353] [1734] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-27 11:39:13.353] [1734] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 1789)
[2025-08-27 11:39:13.353] [1734] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-27 11:39:13.353] [1734] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 1790)
[2025-08-27 11:39:13.353] [1734] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-27 11:39:13.353] [1734] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-27 11:39:13.354] [1734] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 11:39:13.354] [1734] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 11:45:00.898] [1539] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-27 11:45:00.899] [1539] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 11:45:00.899] [1539] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 11:45:00.899] [1539] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 11:45:00.899] [1539] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 11:45:00.899] [1539] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 11:45:00.899] [1539] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 11:45:00.899] [1539] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl3meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 11:45:00.899] [1539] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element EntryPushQEl0meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-27 11:45:00.899] [1539] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element EntryPushQEl0meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-27 11:45:00.899] [1539] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl3meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-27 11:45:00.900] [1786] [HailoRT] [info] [vdevice.cpp:424] [listener_run_in_thread] Shutdown event was signaled in listener_run_in_thread
[2025-08-27 14:39:05.028] [1675] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 14:39:05.032] [1675] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 14:39:05.033] [1675] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 14:39:05.223] [1675] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 14:39:05.224] [1675] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 14:39:05.225] [1675] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 14:39:09.846] [1777] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 14:39:09.848] [1777] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 14:39:09.849] [1777] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 14:39:09.885] [1777] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-27 14:39:10.943] [1777] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-27 14:39:10.944] [1777] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-27 14:39:10.975] [1777] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 14:39:10.975] [1777] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 14:39:11.064] [1777] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-27 14:39:11.066] [1777] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-27 14:39:11.067] [1777] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 14:39:11.067] [1777] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-27 14:39:11.067] [1777] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-27 14:39:11.068] [1777] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-27 14:39:11.068] [1777] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-27 14:39:11.068] [1777] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-27 14:39:11.068] [1777] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 1832)
[2025-08-27 14:39:11.068] [1777] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-27 14:39:11.068] [1777] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 1833)
[2025-08-27 14:39:11.068] [1777] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-27 14:39:11.068] [1777] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 1834)
[2025-08-27 14:39:11.068] [1777] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-27 14:39:11.068] [1777] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-27 14:39:11.068] [1777] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-27 14:39:11.068] [1777] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-28 04:15:42.524] [1830] [HailoRT] [info] [vdevice.cpp:424] [listener_run_in_thread] Shutdown event was signaled in listener_run_in_thread
[2025-08-28 04:16:50.476] [1833] [HailoRT] [error] [hailort_rpc_client.cpp:1553] [ConfiguredNetworkGroup_infer_async] CHECK_SUCCESS failed with status=HAILO_NOT_FOUND(61)
[2025-08-28 04:16:50.477] [1833] [HailoRT] [error] [network_group_client.cpp:697] [infer_async] CHECK_SUCCESS failed with status=HAILO_NOT_FOUND(61)
[2025-08-28 04:16:50.477] [1833] [HailoRT] [error] [pipeline_internal.cpp:26] [handle_non_recoverable_async_error] Non-recoverable Async Infer Pipeline error. status error code: HAILO_NOT_FOUND(61)
[2025-08-28 04:16:50.477] [1833] [HailoRT] [error] [async_infer_runner.cpp:88] [shutdown] Shutting down the pipeline with status HAILO_NOT_FOUND(61)
[2025-08-28 04:16:50.477] [1833] [HailoRT] [error] [network_group_client.cpp:258] [shutdown] CHECK_SUCCESS failed with status=HAILO_NOT_FOUND(61) - Failed to shutdown
[2025-08-28 04:16:50.477] [1833] [HailoRT] [error] [multi_io_elements.cpp:1032] [execute_terminate] CHECK_SUCCESS failed with status=HAILO_NOT_FOUND(61)
[2025-08-28 04:16:50.477] [1833] [HailoRT] [error] [pipeline.cpp:1034] [execute] CHECK_SUCCESS failed with status=HAILO_NOT_FOUND(61)
[2025-08-28 04:16:50.477] [1833] [HailoRT] [error] [queue_elements.cpp:599] [execute_terminate] CHECK_SUCCESS failed with status=HAILO_NOT_FOUND(61)
[2025-08-28 04:16:50.477] [1833] [HailoRT] [error] [pipeline.cpp:1034] [execute] CHECK_SUCCESS failed with status=HAILO_NOT_FOUND(61)
[2025-08-28 04:16:50.477] [1833] [HailoRT] [error] [pipeline.cpp:1034] [execute] CHECK_SUCCESS failed with status=HAILO_NOT_FOUND(61)
[2025-08-28 04:16:50.477] [1833] [HailoRT] [error] [queue_elements.cpp:599] [execute_terminate] CHECK_SUCCESS failed with status=HAILO_NOT_FOUND(61)
[2025-08-28 04:16:50.477] [1833] [HailoRT] [critical] [async_infer_runner.cpp:99] [shutdown] Executing pipeline terminate failed with status HAILO_NOT_FOUND(61)
[2025-08-28 04:16:50.478] [1833] [HailoRT] [info] [queue_elements.cpp:497] [operator()] Thread in element PushQEl3meljune_exponent_v8/input_layer1 is not running anymore, exiting..
[2025-08-28 04:16:50.543] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_NOT_FOUND(61) - Can't handle inference request since pipeline status is HAILO_NOT_FOUND(61).
[2025-08-28 04:16:50.543] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_NOT_FOUND(61)
[2025-08-28 04:16:50.544] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:50.670] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:50.670] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:50.670] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:50.704] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:50.704] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:50.704] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:50.774] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:50.774] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:50.774] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:50.814] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:50.814] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:50.814] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:50.872] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:50.873] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:50.873] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:50.923] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:50.923] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:50.923] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:50.973] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:50.973] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:50.973] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:51.036] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:51.036] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:51.036] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:51.174] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:51.174] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:51.174] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:51.205] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:51.205] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:51.205] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:51.375] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:51.375] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:51.375] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:51.411] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:51.411] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:51.411] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:51.577] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:51.577] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:51.577] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:51.620] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:51.620] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:51.620] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:51.878] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:51.878] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:51.878] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:52.022] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:52.022] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:52.022] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:52.085] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:52.085] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:52.085] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:52.147] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:52.147] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:52.147] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:52.202] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:52.202] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:52.202] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:52.258] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:52.258] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:52.258] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:52.312] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:52.312] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:52.312] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:52.370] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:52.370] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:52.370] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:52.426] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:52.426] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:52.426] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:52.484] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:52.484] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:52.484] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:52.583] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:52.583] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:52.583] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:52.617] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:52.617] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:52.617] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:52.785] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:52.785] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:52.785] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:52.826] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:52.826] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:52.826] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:52.985] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:52.986] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:52.986] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:53.029] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:53.029] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:53.029] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:53.089] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:53.089] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:53.089] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:53.145] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:53.145] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:53.145] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:53.288] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:53.288] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:53.288] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:53.331] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:53.331] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:53.331] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:53.392] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:53.392] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:53.392] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:53.456] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:53.456] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:53.456] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:53.515] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:53.515] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:53.515] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:53.571] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:53.571] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:53.571] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:53.691] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:53.691] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:53.691] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:53.722] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:53.722] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:53.722] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:53.795] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:53.795] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:53.795] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:53.830] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:53.830] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:53.830] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:53.894] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:53.894] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:53.894] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:53.934] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:53.934] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:53.934] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:53.994] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:53.994] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:53.994] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:54.055] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:54.055] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:54.055] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:54.194] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:54.194] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:54.194] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:54.225] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:54.225] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:54.225] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:54.395] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:54.395] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:54.395] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:54.439] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:54.439] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:54.439] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:54.500] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:54.501] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:54.501] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:54.555] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:54.555] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:54.555] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:54.612] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:54.612] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:54.612] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:54.667] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:54.667] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:54.667] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:54.720] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:54.720] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:54.720] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:54.780] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:54.780] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:54.780] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:54.899] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:54.899] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:54.899] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:54.931] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:54.931] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:54.931] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:55.001] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:55.001] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:55.001] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:55.041] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:55.041] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:55.041] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:55.102] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:55.102] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:55.102] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:55.153] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:55.153] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:55.153] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:55.204] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:55.204] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:55.204] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:55.267] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:55.267] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:55.267] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:55.328] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:55.328] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:55.328] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:55.380] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:55.380] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:55.380] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:55.434] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:55.434] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:55.434] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:55.490] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:55.490] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:55.490] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:55.543] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:55.543] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:55.543] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:55.602] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:55.602] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:55.602] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:55.805] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:55.805] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:55.805] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:55.845] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:55.845] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:55.845] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:56.007] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:56.007] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:56.007] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:56.051] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:56.051] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:56.051] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:56.109] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:56.109] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:56.109] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:56.170] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:56.170] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:56.170] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:56.225] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:56.225] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:56.225] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:56.288] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:56.288] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:56.288] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:56.342] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:56.342] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:56.342] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:56.402] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:56.402] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:56.402] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:56.509] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:56.509] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:56.509] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:56.552] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:56.552] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:56.552] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:56.613] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:56.613] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:56.613] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:56.671] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:56.671] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:56.671] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:56.726] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:56.726] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:56.726] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:56.765] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:56.765] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:56.765] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:56.820] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:56.820] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:56.820] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:56.865] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:56.865] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:56.865] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:57.113] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:57.113] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:57.113] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:57.149] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:57.149] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:57.149] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:57.216] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:57.216] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:57.216] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:57.264] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:57.265] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:57.265] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:57.322] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:57.322] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:57.322] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:57.387] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:57.387] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:57.387] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:57.517] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:57.517] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:57.517] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:57.549] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:57.549] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:57.549] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:57.617] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:57.617] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:57.617] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:57.652] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:57.652] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:57.652] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:57.720] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:57.720] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:57.720] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:57.766] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:57.766] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:57.766] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:57.918] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:57.918] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:57.918] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:57.955] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:57.955] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:57.955] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:58.120] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:58.120] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:58.120] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:58.160] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:58.160] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:58.160] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:58.247] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:58.247] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:58.248] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:58.307] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:58.307] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:58.307] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:58.523] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:58.523] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:58.523] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:58.562] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:58.562] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:58.562] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:58.724] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:58.724] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:58.724] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:58.770] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:58.771] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:58.771] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:58.927] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:58.927] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:58.927] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:58.974] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:58.974] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:58.974] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:59.029] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:59.029] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:59.029] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:59.081] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:59.081] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:59.081] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:59.136] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:59.136] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:59.136] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:59.195] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:59.195] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:59.195] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:59.250] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:59.250] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:59.250] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:59.308] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:59.308] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:59.308] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:59.529] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:59.529] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:59.529] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:59.564] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:59.564] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:59.564] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:59.631] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:59.631] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:59.631] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:59.672] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:59.672] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:59.672] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:59.932] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:59.932] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:59.932] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:16:59.969] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:16:59.969] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:16:59.969] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:00.035] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:00.035] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:00.035] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:00.097] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:00.097] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:00.097] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:00.234] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:00.234] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:00.234] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:00.265] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:00.265] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:00.265] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:00.337] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:00.337] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:00.337] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:00.377] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:00.378] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:00.378] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:00.537] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:00.537] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:00.537] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:00.578] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:00.578] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:00.578] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:00.838] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:00.838] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:00.838] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:00.875] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:00.875] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:00.875] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:00.958] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:00.958] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:00.958] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:01.018] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:01.018] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:01.018] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:01.140] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:01.140] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:01.140] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:01.184] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:01.185] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:01.185] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:01.243] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:01.243] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:01.243] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:01.297] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:01.297] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:01.297] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:01.442] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:01.442] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:01.442] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:01.481] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:01.481] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:01.481] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:01.544] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:01.544] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:01.544] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:01.597] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:01.597] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:01.597] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:01.651] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:01.652] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:01.652] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:01.713] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:01.713] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:01.713] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:01.763] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:01.763] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:01.763] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:01.828] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:01.828] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:01.828] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:01.948] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:01.948] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:01.948] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:01.995] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:01.995] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:01.995] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:02.048] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:02.048] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:02.048] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:02.095] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:02.095] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:02.095] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:02.348] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:02.348] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:02.348] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:02.385] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:02.385] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:02.385] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:02.650] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:02.650] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:02.650] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:02.682] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:02.682] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:02.682] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:02.752] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:02.752] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:02.752] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:02.790] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:02.790] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:02.790] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:02.854] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:02.854] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:02.854] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:02.914] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:02.914] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:02.914] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:03.154] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:03.154] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:03.154] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:03.195] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:03.195] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:03.195] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:03.556] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:03.556] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:03.556] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:03.600] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:03.600] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:03.600] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:03.661] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:03.661] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:03.661] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:03.715] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:03.715] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:03.715] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:03.770] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:03.770] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:03.770] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:03.826] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:03.826] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:03.826] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:03.876] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:03.876] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:03.876] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:03.942] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:03.942] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:03.942] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:03.998] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:03.998] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:03.998] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:04.053] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:04.053] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:04.053] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:04.160] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:04.160] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:04.160] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:04.203] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:04.203] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:04.203] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:04.264] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:04.264] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:04.264] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:04.319] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:04.320] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:04.320] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:04.563] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:04.563] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:04.563] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:04.598] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:04.598] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:04.598] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:04.665] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:04.665] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:04.665] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:04.704] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:04.704] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:04.704] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:04.767] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:04.767] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:04.767] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:04.811] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:04.811] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:04.811] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:04.866] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:04.866] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:04.866] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:04.921] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:04.921] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:04.921] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:05.066] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:05.066] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:05.066] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:05.105] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:05.105] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:05.105] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:05.267] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:05.267] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:05.267] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:05.313] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:05.313] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:05.313] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:05.469] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:05.469] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:05.469] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:05.501] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:05.501] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:05.501] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:05.577] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:05.577] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:05.577] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:05.613] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:05.613] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:05.613] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:05.771] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:05.771] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:05.771] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:05.814] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:05.814] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:05.814] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:05.874] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:05.874] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:05.874] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:05.912] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:05.912] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:05.912] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:06.073] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:06.073] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:06.074] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:06.110] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:06.110] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:06.110] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:06.274] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:06.274] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:06.274] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:06.317] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:06.317] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:06.317] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:06.375] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:06.375] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:06.375] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:06.416] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:06.416] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:06.416] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:06.480] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:06.480] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:06.480] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:06.539] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:06.539] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:06.539] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:06.596] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:06.596] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:06.596] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:06.658] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:06.658] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:06.658] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:06.778] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:06.778] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:06.778] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:06.821] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:06.821] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:06.821] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:06.881] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:06.881] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:06.881] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:06.938] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:06.938] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:06.938] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:06.993] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:06.993] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:06.993] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:07.051] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:07.051] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:07.051] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:07.181] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:07.181] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:07.181] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:07.228] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:07.228] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:07.228] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:07.382] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:07.382] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:07.382] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:07.417] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:07.417] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:07.417] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:07.583] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:07.583] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:07.583] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:07.619] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:07.619] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:07.619] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:07.685] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:07.685] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:07.685] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:07.735] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:07.735] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:07.735] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:07.986] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:07.986] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:07.986] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:08.024] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:08.024] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:08.024] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:08.187] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:08.187] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:08.187] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:08.230] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:08.230] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:08.230] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:08.291] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:08.291] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:08.291] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:08.354] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:08.354] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:08.354] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:08.408] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:08.408] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:08.408] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:08.477] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:08.477] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:08.477] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:08.534] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:08.534] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:08.534] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:08.583] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:08.583] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:08.583] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:08.638] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:08.638] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:08.638] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:08.697] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:08.697] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:08.697] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:08.746] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:08.746] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:08.746] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:08.804] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:08.804] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:08.804] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:08.893] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:08.893] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:08.893] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:08.932] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:08.932] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:08.932] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:08.994] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:08.994] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:08.994] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:09.049] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:09.049] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:09.049] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:10.201] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:10.201] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:10.201] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:10.239] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:10.239] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:10.239] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:10.403] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:10.403] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:10.403] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:10.443] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:10.443] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:10.443] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:10.603] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:10.603] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:10.603] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:10.643] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:10.643] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:10.643] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:10.726] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:10.727] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:10.727] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:10.783] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:10.783] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:10.783] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:10.838] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:10.838] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:10.838] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:10.884] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:10.884] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:10.884] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:10.951] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:10.951] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:10.951] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:10.999] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:10.999] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:10.999] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:11.051] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:11.051] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:11.052] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:11.111] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:11.111] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:11.111] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:11.171] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:11.171] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:11.171] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:11.227] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:11.227] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:11.227] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:11.309] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:11.309] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:11.309] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:11.343] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:11.343] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:11.343] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:11.509] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:11.509] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:11.509] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:11.547] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:11.547] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:11.547] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:11.711] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:11.711] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:11.711] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:11.747] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:11.747] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:11.747] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:11.814] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:11.814] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:11.814] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:11.858] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:11.858] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:11.858] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:12.012] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:12.013] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:12.013] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:12.050] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:12.050] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:12.050] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:12.214] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:12.214] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:12.214] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:12.249] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:12.249] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:12.249] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:12.415] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:12.416] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:12.416] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:12.473] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:12.473] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:12.473] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:12.535] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:12.535] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:12.535] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:12.589] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:12.589] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:12.589] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:12.717] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:12.717] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:12.717] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:12.751] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:12.751] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:12.751] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:12.919] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:12.919] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:12.919] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:12.960] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:12.960] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:12.960] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:13.021] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:13.021] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:13.021] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:13.077] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:13.077] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:13.077] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:13.321] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:13.321] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:13.321] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:13.359] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:13.359] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:13.359] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:13.623] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:13.623] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:13.623] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:13.669] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:13.669] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:13.669] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:13.825] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:13.825] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:13.825] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:13.863] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:13.863] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:13.863] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:14.027] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:14.027] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:14.027] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:14.064] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:14.064] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:14.064] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:14.129] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:14.129] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:14.129] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:14.174] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:14.174] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:14.174] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:14.230] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:14.230] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:14.230] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:14.288] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:14.288] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:14.288] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:14.530] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:14.530] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:14.530] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:14.581] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:14.581] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:14.581] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:14.731] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:14.731] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:14.731] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:14.763] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:14.763] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:14.763] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:14.832] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:14.833] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:14.833] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:14.871] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:14.871] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:14.871] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:15.033] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:15.033] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:15.033] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:15.077] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:15.077] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:15.077] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:15.136] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:15.136] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:15.136] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:15.193] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:15.193] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:15.193] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:15.335] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:15.335] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:15.335] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:15.377] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:15.377] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:15.377] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:15.438] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:15.438] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:15.438] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:15.492] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:15.492] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:15.492] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:15.739] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:15.740] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:15.740] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:15.784] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:15.784] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:15.784] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:15.939] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:15.939] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:15.939] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:15.983] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:15.983] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:15.983] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:16.140] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:16.140] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:16.140] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:16.177] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:16.177] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:16.177] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:16.342] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:16.342] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:16.342] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:16.378] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:16.378] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:16.378] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:16.543] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:16.543] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:16.543] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:16.578] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:16.578] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:16.578] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:16.744] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:16.744] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:16.744] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:16.780] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:16.780] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:16.780] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:16.946] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:16.946] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:16.946] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:16.983] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:16.983] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:16.983] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:17.147] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:17.147] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:17.147] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:17.188] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:17.188] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:17.188] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:17.348] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:17.348] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:17.348] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:17.389] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:17.389] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:17.389] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:17.450] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:17.450] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:17.450] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:17.511] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:17.511] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:17.511] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:17.568] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:17.568] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:17.568] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:17.614] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:17.614] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:17.614] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:17.689] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:17.689] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:17.689] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:17.752] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:17.752] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:17.752] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:17.952] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:17.953] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:17.953] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:17.992] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:17.992] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:17.992] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:18.054] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:18.055] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:18.055] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:18.106] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:18.106] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:18.106] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:18.254] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:18.254] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:18.254] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:18.288] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:18.288] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:18.288] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:18.358] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:18.358] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:18.358] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:18.398] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:18.398] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:18.398] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:18.556] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:18.557] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:18.557] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:18.598] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:18.598] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:18.598] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:18.660] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:18.660] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:18.660] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:18.714] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:18.714] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:18.714] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:18.959] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:18.959] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:18.959] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:18.995] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:18.995] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:18.995] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:19.160] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:19.160] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:19.160] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:19.199] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:19.199] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:19.199] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:19.462] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:19.462] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:19.462] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:19.498] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:19.499] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:19.499] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:19.566] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:19.566] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:19.566] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:19.609] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:19.609] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:19.609] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:19.666] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:19.666] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:19.666] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:19.725] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:19.725] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:19.725] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:19.781] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:19.781] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:19.781] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:19.839] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:19.839] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:19.839] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:19.895] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:19.895] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:19.895] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:19.961] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:19.962] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:19.962] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:20.016] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:20.016] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:20.016] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:20.074] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:20.074] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:20.074] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:20.124] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:20.124] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:20.124] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:20.185] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:20.185] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:20.185] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:20.254] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:20.254] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:20.254] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:20.309] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:20.309] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:20.309] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:20.366] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:20.366] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:20.366] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:20.430] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:20.430] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:20.430] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:20.492] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:20.492] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:20.492] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:20.564] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:20.564] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:20.564] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:20.617] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:20.617] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:20.617] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:20.688] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:20.688] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:20.688] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:20.741] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:20.741] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:20.741] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:20.817] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:20.817] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:20.817] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:20.877] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:20.877] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:20.877] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:20.950] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:20.950] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:20.950] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:21.006] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:21.006] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:21.006] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:21.069] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:21.069] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:21.069] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:21.274] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:21.274] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:21.274] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:21.308] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:21.308] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:21.308] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:21.378] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:21.378] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:21.378] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:21.429] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:21.429] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:21.429] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:21.576] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:21.576] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:21.576] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:21.613] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:21.613] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:21.613] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:21.680] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:21.680] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:21.680] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:21.727] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:21.727] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:21.727] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:21.784] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:21.784] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:21.784] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:21.848] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:21.848] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:21.848] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:21.909] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:21.909] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:21.909] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:21.969] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:21.969] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:21.969] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:22.018] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:22.018] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:22.018] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:22.069] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:22.070] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:22.070] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:22.282] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:22.282] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:22.282] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:22.339] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:22.339] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:22.339] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:22.397] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:22.397] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:22.397] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:22.454] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:22.454] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:22.454] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:22.584] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:22.584] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:22.584] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:22.620] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:22.620] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:22.620] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:22.684] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:22.684] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:22.684] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:22.723] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:22.723] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:22.723] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:22.788] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:22.788] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:22.788] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:22.843] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:22.843] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:22.843] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:23.086] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:23.086] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:23.086] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:23.123] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:23.123] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:23.123] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:23.287] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:23.287] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:23.287] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:23.322] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:23.322] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:23.322] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:23.489] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:23.489] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:23.489] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:23.526] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:23.526] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:23.526] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:23.690] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:23.690] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:23.690] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:23.755] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:23.755] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:23.755] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:23.891] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:23.891] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:23.891] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:23.924] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:23.924] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:23.924] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:24.092] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:24.092] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:24.092] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:24.129] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:24.129] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:24.129] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:24.293] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:24.293] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:24.293] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:24.330] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:24.330] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:24.330] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:24.398] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:24.398] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:24.398] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:24.440] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:24.440] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:24.440] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:24.595] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:24.595] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:24.596] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:24.640] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:24.641] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:24.641] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:24.700] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:24.700] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:24.700] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:24.757] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:24.757] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:24.757] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:24.812] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:24.813] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:24.813] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:24.869] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:24.869] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:24.869] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:25.099] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:25.099] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:25.099] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:25.135] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:25.136] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:25.136] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:25.201] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:25.201] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:25.201] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:25.241] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:25.241] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:25.241] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:25.302] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:25.302] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:25.302] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:25.352] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:25.352] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:25.352] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:25.401] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:25.401] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:25.401] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:25.461] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:25.461] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:25.461] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:25.515] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:25.515] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:25.515] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:25.569] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:25.569] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:25.569] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:25.805] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:25.805] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:25.805] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:25.852] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:25.852] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:25.852] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:26.105] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:26.105] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:26.105] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:26.152] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:26.152] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:26.152] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:26.206] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:26.206] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:26.206] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:26.271] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:26.271] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:26.271] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:26.508] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:26.508] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:26.508] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:26.560] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:26.560] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:26.560] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:26.713] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:26.713] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:26.713] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:26.775] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:26.775] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:26.775] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:27.011] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:27.012] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:27.012] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:27.053] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:27.053] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:27.053] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:27.117] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:27.117] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:27.117] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:27.168] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:27.168] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:27.168] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:27.218] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:27.218] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:27.219] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:27.284] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:27.284] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:27.284] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:27.339] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:27.339] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:27.339] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:27.398] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:27.398] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:27.398] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:27.450] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:27.450] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:27.450] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:27.511] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:27.511] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:27.511] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:27.566] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:27.567] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:27.567] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:27.633] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:27.633] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:27.633] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:27.917] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:27.917] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:27.917] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:27.954] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:27.954] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:27.954] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:28.119] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:28.119] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:28.119] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:28.160] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:28.160] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:28.160] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:28.235] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:28.235] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:28.235] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:28.294] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:28.294] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:28.294] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:28.522] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:28.522] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:28.522] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:28.562] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:28.562] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:28.562] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:28.638] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:28.638] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:28.638] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:28.702] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:28.702] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:28.702] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:28.784] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:28.784] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:28.784] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:28.818] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:28.818] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:28.818] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:28.927] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:28.927] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:28.927] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:28.971] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:28.971] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:28.971] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:29.125] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:29.125] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:29.125] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:29.171] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:29.171] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:29.171] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:29.229] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:29.229] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:29.229] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:29.280] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:29.280] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:29.280] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:29.330] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:29.330] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:29.330] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:29.390] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:29.390] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:29.390] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:29.528] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:29.528] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:29.528] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:29.573] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:29.573] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:29.573] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:29.631] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:29.631] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:29.631] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:29.686] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:29.686] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:29.686] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:29.930] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:29.931] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:29.931] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:29.967] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:29.967] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:29.967] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:30.132] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:30.132] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:30.132] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:30.178] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:30.178] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:30.178] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:30.233] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:30.233] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:30.233] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:30.290] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:30.290] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:30.290] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:30.534] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:30.534] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:30.534] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:30.570] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:30.570] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:30.570] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:30.738] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:30.738] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:30.738] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:30.787] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:30.788] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:30.788] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:30.842] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:30.843] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:30.843] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:30.912] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:30.912] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:30.912] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:30.969] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:30.969] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:30.969] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:31.022] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:31.022] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:31.022] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:31.140] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:31.140] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:31.140] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:31.182] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:31.182] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:31.182] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:31.262] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:31.262] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:31.262] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:31.316] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:31.316] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:31.316] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:31.541] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:31.541] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:31.541] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:31.579] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:31.579] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:31.579] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:31.843] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:31.843] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:31.843] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:31.874] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:31.874] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:31.874] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:31.946] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:31.946] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:31.946] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:31.984] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:31.984] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:31.984] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:32.145] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:32.145] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:32.145] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:32.181] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:32.181] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:32.181] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:32.251] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:32.251] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:32.251] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:32.291] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:32.291] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:32.291] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:32.347] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:32.347] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:32.347] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:32.407] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:32.407] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:32.407] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:32.461] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:32.461] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:32.461] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:32.511] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:32.511] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:32.511] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:32.579] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:32.579] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:32.579] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:32.635] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:32.635] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:32.635] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:32.685] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:32.685] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:32.685] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:32.747] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:32.747] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:32.747] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:32.801] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:32.801] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:32.801] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:32.868] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:32.868] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:32.868] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:32.919] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:32.919] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:32.919] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:32.981] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:32.981] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:32.981] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:33.151] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:33.151] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:33.151] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:33.189] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:33.189] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:33.189] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:33.353] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:33.353] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:33.353] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:33.392] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:33.392] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:33.392] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:33.456] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:33.456] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:33.456] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:33.510] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:33.510] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:33.510] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:33.655] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:33.655] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:33.655] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:33.701] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:33.701] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:33.701] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:33.762] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:33.763] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:33.763] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:33.824] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:33.824] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:33.824] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:33.957] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:33.957] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:33.957] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:33.990] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:33.990] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:33.990] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:34.158] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:34.158] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:34.158] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:34.196] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:34.196] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:34.196] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:34.260] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:34.260] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:34.260] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:34.305] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:34.305] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:34.305] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:34.366] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:34.366] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:34.366] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:34.412] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:34.413] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:34.413] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:34.478] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:34.478] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:34.478] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:34.539] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:34.539] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:34.539] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:34.661] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:34.662] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:34.662] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:34.693] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:34.693] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:34.693] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:34.764] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:34.764] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:34.764] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:34.807] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:34.807] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:34.807] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:34.865] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:34.866] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:34.866] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:34.920] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:34.920] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:34.920] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:35.064] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:35.064] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:35.064] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:35.106] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:35.106] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:35.106] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:35.167] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:35.167] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:35.167] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:35.222] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:35.222] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:35.222] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:35.366] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:35.366] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:35.366] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:35.407] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:35.407] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:35.407] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:35.468] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:35.468] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:35.468] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:35.523] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:35.523] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:35.523] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:35.577] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:35.577] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:35.577] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:35.629] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:35.629] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:35.629] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:35.681] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:35.681] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:35.681] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:35.725] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:35.725] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:35.725] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:35.776] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:35.776] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:35.776] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:35.840] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:35.840] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:35.840] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:35.970] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:35.970] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:35.970] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:36.005] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:36.005] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:36.005] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:36.171] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:36.171] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:36.171] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:36.212] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:36.212] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:36.212] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:36.273] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:36.274] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:36.274] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:36.312] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:36.312] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:36.312] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:36.474] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:36.474] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:36.474] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:36.529] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:36.529] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:36.529] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:36.581] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:36.581] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:36.581] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:36.640] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:36.640] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:36.640] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:36.689] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:36.689] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:36.689] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:36.752] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:36.752] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:36.752] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:36.806] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:36.806] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:36.806] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:36.869] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:36.869] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:36.869] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:36.978] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:36.978] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:36.978] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:37.023] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:37.023] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:37.023] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:37.080] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:37.080] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:37.081] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:37.135] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:37.135] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:37.135] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:37.279] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:37.279] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:37.279] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:37.313] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:37.313] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:37.313] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:37.480] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:37.480] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:37.480] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:37.515] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:37.515] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:37.515] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:37.584] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:37.584] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:37.584] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:37.621] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:37.621] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:37.621] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:37.683] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:37.683] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:37.683] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:37.737] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:37.737] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:37.737] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:37.788] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:37.788] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:37.788] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:37.846] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:37.846] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:37.846] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:37.984] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:37.984] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:37.984] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:38.047] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:38.048] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:38.048] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:38.185] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:38.185] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:38.185] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:38.216] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:38.216] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:38.216] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:38.286] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:38.286] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:38.286] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:38.324] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:38.324] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:38.324] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:38.387] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:38.387] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:38.387] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:38.441] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:38.442] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:38.442] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:38.500] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:38.500] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:38.500] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:38.553] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:38.553] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:38.553] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:38.689] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:38.689] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:38.689] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:38.736] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:38.736] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:38.736] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:38.793] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:38.793] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:38.793] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:38.854] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:38.854] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:38.854] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:38.991] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:38.991] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:38.991] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:39.024] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:39.024] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:39.024] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:39.093] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:39.093] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:39.093] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:39.143] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:39.143] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:39.143] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:39.293] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:39.293] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:39.293] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:39.332] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:39.332] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:39.332] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:39.594] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:39.594] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:39.594] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:39.633] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:39.633] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:39.633] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:39.698] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:39.698] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:39.699] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:39.755] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:39.755] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:39.755] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:39.811] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:39.811] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:39.811] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:39.871] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:39.871] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:39.871] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:40.097] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:40.098] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:40.098] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:40.140] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:40.140] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:40.140] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:40.218] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:40.218] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:40.218] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:40.279] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:40.279] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:40.279] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:40.399] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:40.399] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:40.399] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:40.431] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:40.431] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:40.431] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:40.600] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:40.600] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:40.600] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:40.646] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:40.646] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:40.646] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:40.704] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:40.704] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:40.704] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:40.755] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:40.755] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:40.755] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:40.902] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:40.902] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:40.902] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:40.938] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:40.938] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:40.938] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:41.103] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:41.103] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:41.103] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:41.138] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:41.138] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:41.138] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:41.305] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:41.305] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:41.306] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:41.343] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:41.343] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:41.343] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:41.409] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:41.409] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:41.409] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:41.462] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:41.462] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:41.462] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:41.509] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:41.509] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:41.509] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:41.575] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:41.575] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:41.575] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:41.708] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:41.708] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:41.708] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:41.747] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:41.747] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:41.747] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:41.811] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:41.811] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:41.811] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:41.859] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:41.859] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:41.859] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:42.110] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:42.110] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:42.110] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:42.145] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:42.145] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:42.145] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:42.311] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:42.311] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:42.311] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:42.353] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:42.353] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:42.353] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:42.414] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:42.414] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:42.414] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:42.476] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:42.476] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:42.476] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:42.532] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:42.532] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:42.532] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:42.592] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:42.592] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:42.592] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:42.643] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:42.643] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:42.643] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:42.703] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:42.703] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:42.703] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:42.915] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:42.915] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:42.915] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:42.950] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:42.950] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:42.950] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:43.117] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:43.117] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:43.117] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:43.152] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:43.152] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:43.152] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:43.221] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:43.221] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:43.221] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:43.265] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:43.265] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:43.265] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:43.319] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:43.319] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:43.319] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:43.366] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:43.366] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:43.366] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:43.427] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:43.427] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:43.427] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:43.488] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:43.488] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:43.488] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:43.725] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:43.725] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:43.725] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:43.780] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:43.780] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:43.780] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:43.923] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:43.923] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:43.923] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:43.959] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:43.959] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:43.959] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:44.124] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:44.124] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:44.124] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:44.166] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:44.166] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:44.166] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:44.325] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:44.325] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:44.325] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:44.367] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:44.367] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:44.367] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:44.428] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:44.428] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:44.428] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:44.472] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:44.472] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:44.472] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:44.527] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:44.527] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:44.527] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:44.583] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:44.583] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:44.583] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:44.828] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:44.828] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:44.828] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:44.862] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:44.862] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:44.862] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:44.932] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:44.932] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:44.932] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:44.975] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:44.975] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:44.975] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:45.032] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:45.032] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:45.032] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:45.087] [1777] [HailoRT] [error] [async_infer_runner.cpp:286] [run] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63) - Can't handle inference request since pipeline status is HAILO_STREAM_ABORT(63).
[2025-08-28 04:17:45.087] [1777] [HailoRT] [error] [infer_model.cpp:951] [run_async] CHECK_SUCCESS failed with status=HAILO_STREAM_ABORT(63)
[2025-08-28 04:17:45.087] [1777] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:45.275] [1675] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 04:17:45.275] [1675] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-28 04:17:45.275] [1675] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-28 04:17:45.275] [1675] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-28 04:17:45.275] [1675] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-28 04:17:45.275] [1675] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-28 04:17:45.275] [1675] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-28 04:17:45.275] [1675] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl3meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-28 04:17:45.275] [1675] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element EntryPushQEl0meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-28 04:17:45.275] [1675] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element EntryPushQEl0meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-28 04:17:45.275] [1675] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl3meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-28 04:17:45.277] [1675] [HailoRT] [error] [hailort_rpc_client.cpp:307] [VDevice_finish_callback_listener] CHECK_SUCCESS failed with status=HAILO_NOT_FOUND(61)
[2025-08-28 04:17:45.277] [1675] [HailoRT] [error] [vdevice.cpp:451] [finish_listener_thread] CHECK_SUCCESS failed with status=HAILO_NOT_FOUND(61)
[2025-08-28 04:17:45.277] [1675] [HailoRT] [critical] [vdevice.cpp:261] [~VDeviceClient] Failed to finish_listener_thread in VDevice
[2025-08-28 04:17:45.277] [1675] [HailoRT] [error] [hailort_rpc_client.cpp:391] [ConfiguredNetworkGroup_release] CHECK_SUCCESS failed with status=HAILO_NOT_FOUND(61)
[2025-08-28 04:17:45.277] [1675] [HailoRT] [critical] [network_group_client.cpp:107] [~ConfiguredNetworkGroupClient] ConfiguredNetworkGroup_release failed with status: HAILO_NOT_FOUND(61)
[2025-08-28 04:17:45.278] [1675] [HailoRT] [error] [hailort_rpc_client.cpp:96] [VDevice_release] CHECK_SUCCESS failed with status=HAILO_NOT_FOUND(61)
[2025-08-28 04:17:45.278] [1675] [HailoRT] [critical] [vdevice.cpp:277] [~VDeviceClient] VDevice_release failed!
[2025-08-28 05:49:44.591] [1566] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-28 05:49:44.595] [1566] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 05:49:44.596] [1566] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 05:49:44.794] [1566] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-28 05:49:44.795] [1566] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 05:49:44.796] [1566] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 05:59:33.317] [1529] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-28 05:59:33.321] [1529] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 05:59:33.321] [1529] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 05:59:33.524] [1529] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-28 05:59:33.526] [1529] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 05:59:33.526] [1529] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 06:09:02.757] [1572] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-28 06:09:02.760] [1572] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 06:09:02.761] [1572] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 06:09:02.971] [1572] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-28 06:09:02.972] [1572] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 06:09:02.973] [1572] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 11:59:48.914] [1571] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-28 11:59:48.917] [1571] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 11:59:48.918] [1571] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 11:59:49.128] [1571] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-28 11:59:49.129] [1571] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 11:59:49.130] [1571] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 12:00:08.423] [1726] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-28 12:00:08.425] [1726] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 12:00:08.426] [1726] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 12:00:08.470] [1726] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-28 12:00:09.533] [1726] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-28 12:00:09.534] [1726] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 12:00:09.569] [1726] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-28 12:00:09.569] [1726] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-28 12:00:09.670] [1726] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-28 12:00:09.672] [1726] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-28 12:00:09.673] [1726] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-28 12:00:09.673] [1726] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-28 12:00:09.673] [1726] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-28 12:00:09.674] [1726] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-28 12:00:09.675] [1726] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-28 12:00:09.675] [1726] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-28 12:00:09.675] [1726] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 1915)
[2025-08-28 12:00:09.675] [1726] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-28 12:00:09.675] [1726] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 1916)
[2025-08-28 12:00:09.675] [1726] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-28 12:00:09.675] [1726] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 1917)
[2025-08-28 12:00:09.675] [1726] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-28 12:00:09.675] [1726] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-28 12:00:09.675] [1726] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-28 12:00:09.675] [1726] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-28 12:05:12.517] [1571] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-28 12:05:12.518] [1571] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-28 12:05:12.518] [1571] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-28 12:05:12.518] [1571] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-28 12:05:12.518] [1571] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-28 12:05:12.518] [1571] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-28 12:05:12.518] [1571] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-28 12:05:12.518] [1571] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl3meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-28 12:05:12.518] [1571] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element EntryPushQEl0meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-28 12:05:12.518] [1571] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element EntryPushQEl0meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-28 12:05:12.518] [1571] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl3meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-28 12:05:12.519] [1913] [HailoRT] [info] [vdevice.cpp:424] [listener_run_in_thread] Shutdown event was signaled in listener_run_in_thread
[2025-08-28 12:06:05.858] [1569] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-28 12:06:05.861] [1569] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 12:06:05.862] [1569] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 12:06:06.056] [1569] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-28 12:06:06.057] [1569] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 12:06:06.058] [1569] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 12:11:51.110] [1547] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-28 12:11:51.114] [1547] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 12:11:51.115] [1547] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 12:11:51.316] [1547] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-28 12:11:51.318] [1547] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-28 12:11:51.318] [1547] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 15:11:09.792] [1732] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 15:11:09.793] [1732] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 15:11:09.794] [1732] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 15:11:09.836] [1732] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-29 15:11:10.893] [1732] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 15:11:10.894] [1732] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 15:11:10.928] [1732] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 15:11:10.928] [1732] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 15:11:11.016] [1732] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-29 15:11:11.019] [1732] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-29 15:11:11.020] [1732] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-29 15:11:11.020] [1732] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-29 15:11:11.020] [1732] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-29 15:11:11.021] [1732] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-29 15:11:11.022] [1732] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-29 15:11:11.022] [1732] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-29 15:11:11.022] [1732] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 1905)
[2025-08-29 15:11:11.022] [1732] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-29 15:11:11.022] [1732] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 1906)
[2025-08-29 15:11:11.022] [1732] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-29 15:11:11.022] [1732] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 1907)
[2025-08-29 15:11:11.022] [1732] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-29 15:11:11.022] [1732] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-29 15:11:11.022] [1732] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 15:11:11.022] [1732] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 15:12:46.080] [1586] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 15:12:46.084] [1586] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 15:12:46.085] [1586] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 15:12:46.291] [1586] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 15:12:46.292] [1586] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 15:12:46.293] [1586] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 15:13:33.694] [1731] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 15:13:33.696] [1731] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 15:13:33.697] [1731] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 15:13:33.736] [1731] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-29 15:13:34.798] [1731] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 15:13:34.799] [1731] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 15:13:34.843] [1731] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 15:13:34.843] [1731] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 15:13:34.946] [1731] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-29 15:13:34.948] [1731] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-29 15:13:34.949] [1731] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-29 15:13:34.949] [1731] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-29 15:13:34.949] [1731] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-29 15:13:34.950] [1731] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-29 15:13:34.950] [1731] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-29 15:13:34.950] [1731] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-29 15:13:34.950] [1731] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 1869)
[2025-08-29 15:13:34.950] [1731] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-29 15:13:34.950] [1731] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 1870)
[2025-08-29 15:13:34.950] [1731] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-29 15:13:34.950] [1731] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 1871)
[2025-08-29 15:13:34.950] [1731] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-29 15:13:34.950] [1731] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-29 15:13:34.951] [1731] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 15:13:34.951] [1731] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 16:44:04.138] [1579] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 16:44:04.142] [1579] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 16:44:04.143] [1579] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 16:44:04.354] [1579] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 16:44:04.355] [1579] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 16:44:04.356] [1579] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 16:44:18.730] [1729] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 16:44:18.731] [1729] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 16:44:18.732] [1729] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 16:44:18.760] [1729] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-29 16:44:19.818] [1729] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 16:44:19.820] [1729] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 16:44:19.854] [1729] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 16:44:19.854] [1729] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 16:44:19.936] [1729] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-29 16:44:19.938] [1729] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-29 16:44:19.938] [1729] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-29 16:44:19.938] [1729] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-29 16:44:19.939] [1729] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-29 16:44:19.939] [1729] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-29 16:44:19.940] [1729] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-29 16:44:19.940] [1729] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-29 16:44:19.940] [1729] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 1795)
[2025-08-29 16:44:19.940] [1729] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-29 16:44:19.940] [1729] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 1796)
[2025-08-29 16:44:19.940] [1729] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-29 16:44:19.940] [1729] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 1797)
[2025-08-29 16:44:19.940] [1729] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-29 16:44:19.940] [1729] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-29 16:44:19.940] [1729] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 16:44:19.940] [1729] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 16:44:25.830] [1579] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-08-29 16:44:25.830] [1579] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-29 16:44:25.830] [1579] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-29 16:44:25.830] [1579] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-29 16:44:25.830] [1579] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-29 16:44:25.830] [1579] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-29 16:44:25.830] [1579] [HailoRT] [info] [queue_elements.cpp:1131] [execute_deactivate] enqueue() in element MultiPushQEl0YOLOV8-Post-Process was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-29 16:44:25.830] [1579] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl3meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-29 16:44:25.830] [1579] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element EntryPushQEl0meljune_exponent_v8/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-08-29 16:44:25.830] [1579] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element EntryPushQEl0meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-29 16:44:25.830] [1579] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl3meljune_exponent_v8/input_layer1 has 0 frames in his Queue on destruction
[2025-08-29 16:44:25.831] [1793] [HailoRT] [info] [vdevice.cpp:424] [listener_run_in_thread] Shutdown event was signaled in listener_run_in_thread
[2025-08-29 16:57:05.802] [1567] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 16:57:05.805] [1567] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 16:57:05.806] [1567] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 16:57:06.018] [1567] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 16:57:06.019] [1567] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 16:57:06.020] [1567] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 16:57:14.108] [1727] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 16:57:14.109] [1727] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 16:57:14.111] [1727] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 16:57:14.146] [1727] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-29 16:57:15.205] [1727] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 16:57:15.206] [1727] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 16:57:15.237] [1727] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 16:57:15.237] [1727] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 16:57:15.329] [1727] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-29 16:57:15.331] [1727] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-29 16:57:15.332] [1727] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-29 16:57:15.332] [1727] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-29 16:57:15.332] [1727] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-29 16:57:15.332] [1727] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-29 16:57:15.333] [1727] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-29 16:57:15.333] [1727] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-29 16:57:15.333] [1727] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 1785)
[2025-08-29 16:57:15.333] [1727] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-29 16:57:15.333] [1727] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 1786)
[2025-08-29 16:57:15.333] [1727] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-29 16:57:15.333] [1727] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 1787)
[2025-08-29 16:57:15.333] [1727] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-29 16:57:15.333] [1727] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-29 16:57:15.333] [1727] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 16:57:15.333] [1727] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 17:14:06.714] [1561] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 17:14:06.718] [1561] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 17:14:06.719] [1561] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 17:14:06.918] [1561] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 17:14:06.920] [1561] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 17:14:06.921] [1561] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 17:31:28.180] [1728] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 17:31:28.182] [1728] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 17:31:28.183] [1728] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 17:31:28.218] [1728] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: true
[2025-08-29 17:31:29.283] [1728] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 17:31:29.284] [1728] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 17:31:29.316] [1728] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 17:31:29.316] [1728] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 17:31:29.402] [1728] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'meljune_exponent_v8' with params: batch size: 1, power mode: ULTRA_PERFORMANCE, latency: NONE
[2025-08-29 17:31:29.403] [1728] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-08-29 17:31:29.404] [1728] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-29 17:31:29.404] [1728] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl3meljune_exponent_v8/input_layer1 | Reorder - src_order: NHWC, src_shape: (640, 640, 3), dst_order: NHCW, dst_shape: (640, 640, 3))
[2025-08-29 17:31:29.404] [1728] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl3meljune_exponent_v8/input_layer1 | timeout: 10s)
[2025-08-29 17:31:29.405] [1728] [HailoRT] [info] [multi_io_elements.cpp:135] [create] Created (NmsPPMuxEl0YOLOV8-Post-Process | Op YOLOV8, Name: YOLOV8-Post-Process, Score threshold: 0.300, IoU threshold: 0.60, Classes: 2, Cross classes: false, NMS results order: BY_CLASS, Max bboxes per class: 100, Image height: 640, Image width: 640)
[2025-08-29 17:31:29.405] [1728] [HailoRT] [info] [queue_elements.cpp:942] [create] Created (MultiPushQEl0YOLOV8-Post-Process | timeout: 10s)
[2025-08-29 17:31:29.405] [1728] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process)
[2025-08-29 17:31:29.405] [1728] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0meljune_exponent_v8/input_layer1 | inputs: user | outputs: PreInferEl3meljune_exponent_v8/input_layer1(running in thread_id: 2435)
[2025-08-29 17:31:29.405] [1728] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl3meljune_exponent_v8/input_layer1 | inputs: EntryPushQEl0meljune_exponent_v8/input_layer1[0] | outputs: PushQEl3meljune_exponent_v8/input_layer1
[2025-08-29 17:31:29.405] [1728] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl3meljune_exponent_v8/input_layer1 | inputs: PreInferEl3meljune_exponent_v8/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 2436)
[2025-08-29 17:31:29.405] [1728] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl3meljune_exponent_v8/input_layer1[0] | outputs: MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process MultiPushQEl0YOLOV8-Post-Process
[2025-08-29 17:31:29.405] [1728] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] MultiPushQEl0YOLOV8-Post-Process | inputs: AsyncHwEl[0] AsyncHwEl[1] AsyncHwEl[2] AsyncHwEl[3] AsyncHwEl[4] AsyncHwEl[5] | outputs: NmsPPMuxEl0YOLOV8-Post-Process(running in thread_id: 2437)
[2025-08-29 17:31:29.405] [1728] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] NmsPPMuxEl0YOLOV8-Post-Process | inputs: MultiPushQEl0YOLOV8-Post-Process[0] | outputs: LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process
[2025-08-29 17:31:29.405] [1728] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0NmsPPMuxEl0YOLOV8-Post-Process | inputs: NmsPPMuxEl0YOLOV8-Post-Process[0] | outputs: user
[2025-08-29 17:31:29.406] [1728] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 17:31:29.406] [1728] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: meljune_exponent_v8
[2025-08-29 17:48:00.474] [1546] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 17:48:00.477] [1546] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 17:48:00.478] [1546] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 17:48:00.676] [1546] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.12.34+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.12.34-1+rpt1~bookworm (2025-06-26) aarch64
[2025-08-29 17:48:00.677] [1546] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-08-29 17:48:00.678] [1546] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
